{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neurais Recorrentes\n",
    "\n",
    "Antes de iniciarmos com as redes neurais recorrentes, é melhor se acostumar com algumas operações comuns do PyTorch. Vamos iniciar com as suas unidades mais básicas:tensores. Suas principais operações aritméticas, formas de inicialização, tensores \"atualizáveis\" entre outros. Em seguida vamos construir uma simples regressão linear usando apenas tensores. A seguir, construímos uma rede neural usando o módulo `nn` do framework, vendo que a sua construção é exatamente a mesma usada pela rede neural de tensores. Finalmente, vamos entender como criar redes neurais customizáveis por herança da classe `Module` (um dos piores nomes de classe que já vi na vida...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from context import fakenews\n",
    "from fakenews import preprocess as pre\n",
    "import gensim\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensores\n",
    "\n",
    "É a principal estrutura de dado do framework. Ela é essencialmente um array numpy de 3 dimensões. Entretanto, com tensores é possível realizar operações diretamente na GPU aumentando a eficiência dos algoritmos. Além disso, eles permitem que o gradiente seja calculado de forma automática a partir de um parâmetro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9979, 0.5295],\n",
       "         [0.0180, 0.3366],\n",
       "         [0.3373, 0.7002]],\n",
       "\n",
       "        [[0.8437, 0.1855],\n",
       "         [0.4123, 0.9194],\n",
       "         [0.4782, 0.7464]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2, 3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos suporte direto a operações aritméticas assim como no numPy. Podemos realizar adições (`+`), subtrações (`-`), multiplicação por escalar (`*`), transposição (`T` ou `transp()`), produto de hadarmard (`*`), produto interno (`@`), entre outros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.ones(2, 3, 2, dtype=torch.int) * 2\n",
    "I = torch.eye(3, 2, dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2, 2],\n",
       "         [2, 2],\n",
       "         [2, 2]],\n",
       "\n",
       "        [[2, 2],\n",
       "         [2, 2],\n",
       "         [2, 2]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0],\n",
       "        [0, 1],\n",
       "        [0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3, 3],\n",
       "         [3, 3],\n",
       "         [3, 3]],\n",
       "\n",
       "        [[3, 3],\n",
       "         [3, 3],\n",
       "         [3, 3]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A + torch.ones(2, 3, 2, dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2, 0],\n",
       "         [0, 2],\n",
       "         [0, 0]],\n",
       "\n",
       "        [[2, 0],\n",
       "         [0, 2],\n",
       "         [0, 0]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A * I == A @ I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2, 2],\n",
       "         [2, 2],\n",
       "         [2, 2]],\n",
       "\n",
       "        [[2, 2],\n",
       "         [2, 2],\n",
       "         [2, 2]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A @ torch.eye(2, dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[6.2832, 6.2832],\n",
       "         [6.2832, 6.2832],\n",
       "         [6.2832, 6.2832]],\n",
       "\n",
       "        [[6.2832, 6.2832],\n",
       "         [6.2832, 6.2832],\n",
       "         [6.2832, 6.2832]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pi * A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.0242, 2.7475],\n",
       "         [2.2647, 2.4919],\n",
       "         [2.3866, 2.0739]],\n",
       "\n",
       "        [[2.0242, 2.7475],\n",
       "         [2.2647, 2.4919],\n",
       "         [2.3866, 2.0739]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = torch.rand(1, 3, 2)\n",
    "A + rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 2, 2],\n",
       "        [2, 2, 2, 2],\n",
       "        [2, 2, 2, 2]], dtype=torch.int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.view(-1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A execução na GPU não ocorre de forma automática. Primeiro, podemos verificar se o dispositivo é suportado pelo PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thalesaguiar/.pyenv/versions/3.8.2/envs/fakenews.env/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em caso positivo, podemos especificar quais tensores terão suas operações executadas na placa gráfica, definir a execução de tudo por padrão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu = torch.device(\"cuda\")\n",
    "# A.to(gpu)\n",
    "# cuda_tensor = torch.tensor([3, 4, 5], device=gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas operações do python geram uma **view** da coleção. Um exemplo comum são os slices. Essa é uma operação bastante comum no NumPy e praticamente todos os frameworks baseados nele. Entretanto, é importante notar que isso gera uma espécie de **ponteiro** para o vetor original. Isto é, alterações na view são alterações no vetor original, pois a view é nada mais que uma visualização diferente do mesmo espaço de memória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 2],\n",
       "        [2, 2, 2],\n",
       "        [2, 2, 2],\n",
       "        [2, 2, 2]], dtype=torch.int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_view = A.view(-1, 3)\n",
    "a_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[99999,     2,     2],\n",
       "        [    2,     2,     2],\n",
       "        [    2,     2,     2],\n",
       "        [    2,     2,     2]], dtype=torch.int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0, 0, 0] = 99999\n",
    "a_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[99999,     2],\n",
       "         [   55,     2],\n",
       "         [    2,     2]],\n",
       "\n",
       "        [[    2,     2],\n",
       "         [    2,     2],\n",
       "         [    2,     2]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_view[0, 2] = 55\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "para realizar uma cópia, usamos o operador `.clone()`. Assim, é criada uma nova estrutura onde cada elemento é uma cópia dos valores originais, sem preservar qualquer referência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[99999,     2],\n",
       "         [   55,     2],\n",
       "         [    2,     2]], dtype=torch.int32),\n",
       " tensor([[99999,     2],\n",
       "         [   55,     2],\n",
       "         [    2,    33]], dtype=torch.int32))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Acp = A.clone()\n",
    "Acp[0, 2, 1] = 33\n",
    "(A[0], Acp[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Neural\n",
    "\n",
    "O PyTorch permite criar modelos neurais com bastante facilidade e praticidade. Tanto a criação de modelos customizáveis e a grande quantidade de modelos prontos disponíveis é bastante simples. Vamos gerar um conjunto de dados aleatórios para experimentar as funções do framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "\n",
       "         7         8         9         10        11        12  \n",
       "0  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562  \n",
       "1  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439  \n",
       "2  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727  \n",
       "3  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517  \n",
       "4  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, Y = load_boston(return_X_y=True)\n",
    "norm = StandardScaler()\n",
    "Xstd = norm.fit_transform(X)\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(Xstd, Y, test_size=0.3,\n",
    "                                                shuffle=True)\n",
    "Xdf = pd.DataFrame(Xstd)\n",
    "Xdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A base carregada é a Boston-Housing prices, uma das disponíveis diretamente no SkLearn. Agora precisamos transformar os conjuntos para usá-los no PyTorch, ou seja, precisamos criar tensores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4169,  3.5896, -1.4105, -0.2726, -1.3104,  0.9835, -1.8945,  1.8341,\n",
       "          -0.7529, -0.0370, -0.6730,  0.4411, -1.1344],\n",
       "         [-0.3904, -0.4877,  1.5690, -0.2726,  0.5987, -0.8429,  0.9753, -0.9539,\n",
       "          -0.6380,  0.1708,  1.2689,  0.3885,  0.6360]]),\n",
       " tensor([34.9000, 16.2000]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = torch.from_numpy(Xtrain).type(torch.float)\n",
    "Xtest = torch.from_numpy(Xtest).type(torch.float)\n",
    "Ytrain = torch.from_numpy(Ytrain).type(torch.float).flatten()\n",
    "Ytest = torch.from_numpy(Ytest).type(torch.float).flatten()\n",
    "(Xtrain[:2], Ytrain[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os dados devidamente ajustados, vamos criar um modelo de regressão linear usando apenas tensores. Primeiro, definimos os `weights` e em seguida o `bias`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8673, 0.4359, 0.7215, 0.7371, 0.4819, 0.1158, 0.3375, 0.2009, 0.9142,\n",
       "         0.2180, 0.3907, 0.3067, 0.3894]], requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.rand(1, 13, requires_grad=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6014]], requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = torch.rand(1, 1, requires_grad=True)\n",
    "bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O parâmetro `requires_grad` diz ao PyTorch que esse tensor deve ser levado em consideração quando algum otimizador for utilizado. Ou seja, no momento que fazemos a propagação do erro, esse tensor será atualizado.\n",
    "\n",
    "Então, temos o seguinte problema:\n",
    "\n",
    "$$y = D \\times W + b$$\n",
    "\n",
    "Onde $D$ é nossa base (apenas *features*), $W$ são os pesos, $b$ é um bias representando possíveis ruídos/erros obtidos das aproximações e $y$ são nossos valores esperados. Ou seja\n",
    "\n",
    "$$\\hat{y} = D \\times W^{'} + b^{'}$$\n",
    "\n",
    "Sendo $\\hat{y}$ um valor próximo o suficiente de $y$, assim como $W^{'}$ e $b^{'}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4681],\n",
       "        [ 1.6262],\n",
       "        [ 5.0308]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = Xtrain @ weights.T + bias\n",
    "yhat[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X):\n",
    "    return X @ weights.T + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, precisamos definir a função objetivo. Vamos usar um simples Mean Squared Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(565.2597, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqr_diff = (Ytrain - yhat) ** 2\n",
    "torch.sum(sqr_diff) / sqr_diff.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A operação `numel()` retorna a quantidade de elementos do tensor. Vamos criar uma função para calcular o erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(preds, real):\n",
    "    diff = (real - preds) ** 2\n",
    "    return torch.sum(diff) / diff.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para descobrir o quanto atualizar para cada peso, vamos aplicar o *gradient descent*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8673, 0.4359, 0.7215, 0.7371, 0.4819, 0.1158, 0.3375, 0.2009, 0.9142,\n",
       "         0.2180, 0.3907, 0.3067, 0.3894]], requires_grad=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mse(Ytrain, yhat)\n",
    "loss.backward()\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que os valores do tensor não foram atualizados após executar o backpropagation. Isso é porque os valores do gradiente são armazenados no atributo `grad` de cada tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.7873, -0.3379,  3.3922,  3.1683,  3.1507, -1.2797,  1.6849, -2.2740,\n",
       "          5.9151,  5.1550,  2.4426, -3.8842,  2.0310]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, podemos atualizar o tensor com o seu gradiente. Aqui devemos tomar cuidado, pois o PyTorch controla e memoriza todas as operações realizadas nos tensores com `require_grad=True` para utilizar no cálculo dos gradientes. Ao atualizar os parâmetros, não queremos que essa operação seja gravada. Para evitar esse comortamento, podemos usar o operador de contexto `with` com a função `torch.no_grad()`.\n",
    "\n",
    "Esse comportamento é devido a estratégia para automaticamente gerar o gradiente de qualquer estrutura. O PyTorch (e provavelmente outros) transforma o gradiente descendente/backpropagation em um grafo onde cada nó é uma operação. Assim, ele só precisa gerar a derivada de cada nó e aplicar o backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0° 565.2597045898438\n",
      " 25° 253.29234313964844\n",
      " 50° 143.78929138183594\n",
      " 75° 104.25788116455078\n",
      "100° 89.80180358886719\n",
      "125° 84.44068145751953\n",
      "150° 82.41802215576172\n",
      "175° 81.63721466064453\n",
      "200° 81.32584381103516\n",
      "225° 81.19577026367188\n",
      "250° 81.13782501220703\n",
      "275° 81.10980224609375\n",
      "300° 81.09490203857422\n",
      "325° 81.086181640625\n",
      "350° 81.08063507080078\n",
      "375° 81.07685089111328\n",
      "400° 81.07413482666016\n",
      "425° 81.07209777832031\n",
      "450° 81.07054138183594\n",
      "475° 81.06930541992188\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "weights.grad.zero_()\n",
    "bias.grad.zero_()\n",
    "\n",
    "nepochs = 500\n",
    "lrate = 1e-2\n",
    "\n",
    "for epoch in range(nepochs):\n",
    "    predictions = model(Xtrain)\n",
    "    loss = mse(predictions, Ytrain)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        weights -= lrate * weights.grad\n",
    "        bias -= lrate * bias.grad\n",
    "        weights.grad.zero_()\n",
    "        bias.grad.zero_()\n",
    "    if epoch % 25 == 0:\n",
    "        print(f'{epoch:3}° {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(92.3383, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(Xtest)\n",
    "loss = mse(pred, Ytest)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimizador\n",
    "\n",
    "Também podemos selecionar qual tipo de otimizador usaremos para ajustar os parâmetros. O mais comum é o Stochastic Gradient Descent (SGD), mas o PyTorch oferece o Adadelta, Adagrad, RMSProp, entre vários outros dentro do pacote `torch.optim`. Além disso, claro, também podemos customizar e criar o nosso próprio otimizador. Mas essa customização não está dentro do nosso escopo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-08\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcentered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Implements RMSprop algorithm.\n",
       "\n",
       "Proposed by G. Hinton in his\n",
       "`course <https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf>`_.\n",
       "\n",
       "The centered version first appears in `Generating Sequences\n",
       "With Recurrent Neural Networks <https://arxiv.org/pdf/1308.0850v5.pdf>`_.\n",
       "\n",
       "The implementation here takes the square root of the gradient average before\n",
       "adding epsilon (note that TensorFlow interchanges these two operations). The effective\n",
       "learning rate is thus :math:`\\alpha/(\\sqrt{v} + \\epsilon)` where :math:`\\alpha`\n",
       "is the scheduled learning rate and :math:`v` is the weighted moving average\n",
       "of the squared gradient.\n",
       "\n",
       "Arguments:\n",
       "    params (iterable): iterable of parameters to optimize or dicts defining\n",
       "        parameter groups\n",
       "    lr (float, optional): learning rate (default: 1e-2)\n",
       "    momentum (float, optional): momentum factor (default: 0)\n",
       "    alpha (float, optional): smoothing constant (default: 0.99)\n",
       "    eps (float, optional): term added to the denominator to improve\n",
       "        numerical stability (default: 1e-8)\n",
       "    centered (bool, optional) : if ``True``, compute the centered RMSProp,\n",
       "        the gradient is normalized by an estimation of its variance\n",
       "    weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
       "\u001b[0;31mFile:\u001b[0m           ~/.pyenv/versions/3.8.2/envs/fakenews.env/lib/python3.8/site-packages/torch/optim/rmsprop.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?torch.optim.RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em geral, os otimizadores são variações do Gradient Descent/Backpropagation. Mas alguns são melhores para evitar cair em mínimos locais, ou mesmo para reduzir a quantidade de épocas necessárias. Outros, como o Adam, podem aumentar a complexidade da otimização ao utilizar valores diferentes para cada parâmetro, consequentemente aumentando também a flexibilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0897, -0.1303,  0.0116, -0.2762, -0.0097, -0.1162,  0.2734, -0.1749,\n",
      "         -0.1626,  0.0609, -0.0571, -0.0592, -0.1353]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2699], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "network = torch.nn.Linear(13, 1)\n",
    "print(network.weight)\n",
    "print(network.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe acima é uma **layer** linear. Como podemos ver, a sua implementação segue a mesma estrutura que usamos na nossa regressão linear. Usando os pesos e bias como parâmetros (tensores) e o autograd para atualização deles.\n",
    "\n",
    "Outro módulo bastante usado do framework é o `functional`. Ele possui várias implementações de funções, tanto para ativação quanto para definição de funções objetivo. Abaixo, definimos noss função objetivo novamente como a o MSE, sendo que dessa vez usando a implementação do próprio PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "mse_loss(input, target, size_average=None, reduce=None, reduction='mean') -> Tensor\n",
       "\n",
       "Measures the element-wise mean squared error.\n",
       "\n",
       "See :class:`~torch.nn.MSELoss` for details.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.pyenv/versions/3.8.2/envs/fakenews.env/lib/python3.8/site-packages/torch/nn/functional.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mse = torch.nn.functional.mse_loss\n",
    "?mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logo em seguida, o módulo `optim` encapsula uma grande variedade de otimizadores. Abaixo, definimos o mais padrão (SGD) e o Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = torch.optim.SGD(network.parameters(), lr=1e-5)\n",
    "adam = torch.optim.Adam(network.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "\n",
    "PyTorch permite encapsular a base de dados para melhor manipular o treinamento e batches da forma mais \"pythonica\" possível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4169,  3.5896, -1.4105, -0.2726, -1.3104,  0.9835, -1.8945,  1.8341,\n",
       "          -0.7529, -0.0370, -0.6730,  0.4411, -1.1344],\n",
       "         [-0.3904, -0.4877,  1.5690, -0.2726,  0.5987, -0.8429,  0.9753, -0.9539,\n",
       "          -0.6380,  0.1708,  1.2689,  0.3885,  0.6360]]),\n",
       " tensor([34.9000, 16.2000]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensordata = torch.utils.data.TensorDataset(Xtrain, Ytrain)\n",
    "tensordata[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "dtl = torch.utils.data.DataLoader(tensordata, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variável `dtl` é **generator** para a base de dados. Cada iteração sobre ela retorna `batch_size` amostras para treino, assim como seus repectivos valores alvo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento\n",
    "\n",
    "Por fim, para realizarmos o treinamento do nosso modelo, a fórmula é bem parecida com a usada na nossa rede com apenas tensores. Na verdade, essa parte do código para treinamento acaba se tornando um certo padrão para modelos do PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0° 869.1465454101562\n",
      " 25° 932.4745483398438\n",
      " 50° 478.1632080078125\n",
      " 75° 887.9330444335938\n",
      "100° 1426.0372314453125\n",
      "125° 913.5899658203125\n",
      "150° 647.532958984375\n",
      "175° 158.18785095214844\n",
      "200° 384.00115966796875\n",
      "225° 798.8470458984375\n",
      "250° 637.3695678710938\n",
      "275° 279.03741455078125\n",
      "300° 673.9016723632812\n",
      "325° 439.4954528808594\n",
      "350° 318.876220703125\n",
      "375° 395.7188415527344\n",
      "400° 381.6651306152344\n",
      "425° 483.4902038574219\n",
      "450° 264.4954833984375\n",
      "475° 673.796630859375\n"
     ]
    }
   ],
   "source": [
    "nepochs = 500\n",
    "lrate = 1e-5\n",
    "\n",
    "for epoch in range(nepochs):\n",
    "    for Xbatch, Ybatch in dtl:\n",
    "        pred = network(Xbatch)\n",
    "        loss = mse(pred.flatten(), Ybatch)\n",
    "        loss.backward(loss)\n",
    "        adam.step()\n",
    "        adam.zero_grad()\n",
    "    if epoch % 25 == 0:\n",
    "        print(f'{epoch:3}° {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que há uma variação no erro, na qual ele nem sempre está reduzindo. consegue identificar o motivo? O que estamos fazendo de diferente com relação ao nosso modelo com apenas tensores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes custom\n",
    "\n",
    "Usando a classe `Module` (novamente, pior nome possível), podemos, a partir de herança, criar arquiteturas de de redes inimagináveis. Isso deve-se ao grande poder do autograd.tudo que precisamos é definir como os dados são passados em direção a saída da rede, ou seja, o *forward pass*. Tendo em vista que o autograd se encarrega de memorizar como os dados foram propagados para frente, gerando automaticamente as operações que devem ser usados durante o gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, din, dh, dout):\n",
    "        super().__init__()\n",
    "        self.input = torch.nn.Linear(din, dh)\n",
    "        self.hidden = torch.nn.Linear(dh, dout)\n",
    "        self.out = torch.nn.Linear(dout, 1)\n",
    "        self.activation = torch.nn.functional.sigmoid\n",
    "        \n",
    "    def forward(self, data):\n",
    "        l1out = self.activation(self.input(data))\n",
    "        l2out = self.activation(self.hidden(l1out))\n",
    "        pred = self.out(l2out)\n",
    "        return torch.nn.functional.tanh(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acima, definimos uma rede neural com 3 layers, sendo duas camadas sigmoid seguidas de uma camada totalmente conectada a qual realiza a regressão usando uma tangente hiperbólica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 601.2274780273438\n",
      "199 600.5746459960938\n",
      "299 599.9262084960938\n",
      "399 599.281982421875\n",
      "499 598.6421508789062\n",
      "599 598.0067138671875\n",
      "699 597.3755493164062\n",
      "799 596.748779296875\n",
      "899 596.12646484375\n",
      "999 595.5086059570312\n",
      "1099 594.895263671875\n",
      "1199 594.2864990234375\n",
      "1299 593.6821899414062\n",
      "1399 593.0826416015625\n",
      "1499 592.4877319335938\n",
      "1599 591.8973388671875\n",
      "1699 591.311767578125\n",
      "1799 590.7310180664062\n",
      "1899 590.1550903320312\n",
      "1999 589.5839233398438\n"
     ]
    }
   ],
   "source": [
    "model = SigmoidNN(13, 50, 10)\n",
    "\n",
    "criterion = torch.nn.functional.mse_loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "for t in range(2000):\n",
    "    y_pred = model(Xtrain)\n",
    "    loss = criterion(y_pred.flatten(), Ytrain)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
