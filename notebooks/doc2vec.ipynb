{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec\n",
    "\n",
    "O doc2vec, ou Paragraph Embedding foi proposto em [[1](https://arxiv.org/pdf/1405.4053v2.pdf)]. Osautores são os mesmos do word2vec, e a semelhança entre as técnicas também. A extração do doc2vec não se liimita a documentos, podendo ser usada para qualquer sequência de palavras: títulos, parágrafos, tweets, entre outros. A ideia aqui é justamente representar documentos de forma a preservar características como a ordem das palvras, a qual se perde ao usar o BOW ou a média dos w2v.\n",
    "\n",
    "Para isso, as técnicas usadas para d2v são bastante semelhantes ao w2v (SkipGram e CBOW). A diferença é que existe um vetor retido durante todo o processo de treinamento, o **Paragraph Vector**. Esse vetor é usado em todas as etapas de treinamento, ou seja, para toda janela esse vetor está lá, funcionando como um vetor de memória. Ao final do treinamento, temos um vetor que pode representar toda a sequência de palavras.\n",
    "\n",
    "<div text-align=\"center\">\n",
    "    <img src=\"imgs/cbow.png\">\n",
    "    <img src=\"imgs/skip.png\">\n",
    "</div>\n",
    "\n",
    "Portanto, neste notebook vamos analisar como funcionaria nosso modelo usando essas carcterísticas. Portanto, vamos verificar qual a diferença entre modelar o documento inteiro ou cada palavra dele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from context import fakenews\n",
    "from fakenews import preprocess as pre\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, vamos carregar e fazero preprocessamento dos dados, assim como fizemos na aula03. Na verdade, tudo que vem a seguir é praticamente o mesmo código da aula03, com poucas diferenças."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully read data from:\n",
      "Fakes: /home/thales/dev/fakenews/data/Fake.csv\n",
      "Reals: /home/thales/dev/fakenews/data/True.csv\n",
      "Removing rows without text...\n",
      "Removing publisher information...\n",
      "Adding class column...\n",
      "Merging fakes and reals\n",
      "Merging titles and bodies...\n",
      "Removing subjects and date...\n",
      "Tokenizing data...\n",
      "Truncating at 869\n"
     ]
    }
   ],
   "source": [
    "base = '/home/thales/dev/fakenews/'\n",
    "news, labels = pre.run(base + 'data/Fake.csv', base + 'data/True.csv')\n",
    "pre.truncate_news(news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos gerar o modelo doc2vec. A implementação do gensim usa o DBOW (imagem da esquerda no início do notebook). Podemos escolher o tamanho da janela, quantidade de *workers* (jobs), e a dimensão do vetor. Vamos usar uma janela de 5, e dimensão 100. Podem alterar os parâmetros e ver as diferenças nos resultados caso achem necessário. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
    "\n",
    "docs = [TaggedDocument(new, [doc_ID]) for doc_ID, new in enumerate(news)]\n",
    "d2v = Doc2Vec(docs, vector_size=100, window=5, workers=4, min_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o modelo treinado, podemos liberar um cache gerado pelo gensim. Isso é opcional, no nosso caso vamos ignorar isso e vamos direto para a inferência. A inferência é feita usando o método `.infer_vector()` ou `.dv['docID']`. \n",
    "Abaixo podemos ver um exemplo de ambos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.27324262,  0.3813901 , -0.38319057,  0.11611375,  0.37417048,\n",
       "       -0.18729281,  0.05496622, -0.4384446 ,  0.51537293, -0.52938557,\n",
       "       -0.39907634,  0.43492252,  0.445951  , -0.22944959, -0.23032373,\n",
       "       -0.2397254 ,  0.05542371, -0.38546386, -0.31398943, -0.7509162 ,\n",
       "        0.08827436, -0.3443745 , -0.03105517,  0.13167888,  0.226244  ,\n",
       "        0.10663103, -0.00856167,  0.04230334, -0.18538818,  0.3780418 ,\n",
       "        0.60150486,  0.0300507 ,  0.7336161 ,  0.00119405,  0.46444464,\n",
       "       -0.0802251 ,  0.3814574 , -0.40198985,  0.79524857,  0.61929154,\n",
       "       -0.8601831 , -0.23806645,  0.3258657 , -0.17329612, -0.26873192,\n",
       "        0.13025488, -0.51481885,  0.7612322 , -0.04145912, -0.1221593 ,\n",
       "       -0.77204657,  0.18659645,  0.78452194,  0.3940642 , -0.02370133,\n",
       "       -0.2669998 ,  0.24086395, -0.57401484,  0.16611397, -0.32364413,\n",
       "        0.18323654, -0.5698154 ,  0.13754262,  0.5269307 ,  0.29959667,\n",
       "       -0.07940871, -0.16247198,  0.4768695 ,  0.7341448 ,  0.06762858,\n",
       "        0.04298581, -0.3689518 ,  0.23159364, -0.23639245,  0.45957562,\n",
       "        0.5067531 , -0.45591238, -0.0460689 , -0.43475655, -0.1834761 ,\n",
       "        0.12076923, -0.07466914, -0.08258495, -0.04534116, -0.7210071 ,\n",
       "       -0.56694096, -0.4372969 , -0.20105433,  0.04205055, -0.39127043,\n",
       "        0.06583038,  0.10280395,  0.44303787, -0.44868502,  0.3426364 ,\n",
       "       -0.07054218,  0.12412618, -0.0731608 ,  0.6074783 ,  0.29028055],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v.infer_vector(news[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.24089529,  0.0559379 , -0.21807459,  0.19554463,  0.3699122 ,\n",
       "       -0.00879263,  0.00376805, -0.4713308 ,  0.42585188, -0.46749908,\n",
       "       -0.2383313 ,  0.29708573,  0.3939724 , -0.17290026, -0.2450358 ,\n",
       "       -0.2584335 ,  0.07154153, -0.14825585,  0.00512494, -0.25686622,\n",
       "        0.23380998, -0.01894146,  0.0992048 , -0.03271559,  0.26636344,\n",
       "       -0.09601244,  0.0522934 , -0.1950375 ,  0.08511513,  0.24587701,\n",
       "        0.43570092,  0.16508323,  0.7687626 ,  0.06068579,  0.44363174,\n",
       "       -0.20286936,  0.06348096, -0.683628  ,  0.7652566 ,  0.46952638,\n",
       "       -0.7472243 , -0.21879041,  0.18656905, -0.06339938, -0.18011089,\n",
       "        0.05998008, -0.55308354,  0.6702631 , -0.01333776,  0.01400774,\n",
       "       -0.6741057 , -0.05296347,  0.44489664,  0.4068878 ,  0.1300171 ,\n",
       "       -0.2478381 ,  0.2928713 , -0.31014508,  0.20275319, -0.18562911,\n",
       "        0.36592728, -0.51171285,  0.05356467,  0.24336219,  0.08907641,\n",
       "       -0.0480834 , -0.28805616,  0.28691784,  0.64603454, -0.11694378,\n",
       "        0.10151652, -0.28530172, -0.01952516, -0.08962968,  0.4845547 ,\n",
       "        0.4792537 , -0.3370638 ,  0.11748963, -0.14459586,  0.1350027 ,\n",
       "        0.3079805 , -0.42743722, -0.5005193 ,  0.07739138, -0.62388927,\n",
       "       -0.56933665, -0.14750503, -0.14427859,  0.00888819, -0.41259137,\n",
       "        0.11513641,  0.1086576 ,  0.32199115, -0.47007662,  0.08454564,\n",
       "       -0.00486921,  0.11203275,  0.0633496 ,  0.45794436,  0.16243814],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v.docvecs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, o vetor gerado durante o treinamento é obtido a partir do ID do documento, enquanto que a inferência gera um novo vetor baseado nos dados de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v.save('fakes-d2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da mesma forma que fizemos para o w2v, podemos persistir o modelo no disco para uso futuro. A seguir, transformamos os dados (palavras/documentos) nos seus respectivos vetores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44267, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_ids = np.arange(44267, dtype=np.int32)\n",
    "docvecs = np.array([d2v.docvecs[id_] for id_ in doc_ids])\n",
    "docvecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com as features representando cada documento, agora vamos dividir nossa base em treino/test. Vamos repetir as mesmas configurações usadas na extração do word2vec. Dessa forma, podemos comparar os resultados diretamente com os experimentos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.19650473,  0.1908642 ,  0.19341165,  0.32731286,  0.25321385],\n",
       "       [-0.22313836,  0.23449564, -0.11937473,  0.15155253, -0.12210088],\n",
       "       [ 0.12032755,  0.3766597 ,  0.3611389 ,  0.05942689, -0.07596436],\n",
       "       [ 0.0350279 , -0.26440144,  0.12007716,  0.40381876, -0.43361357],\n",
       "       [-0.00980167, -0.0112812 ,  0.02000316,  0.08399785, -0.02749721]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = train_test_split(docvecs, labels, test_size=0.3, shuffle=True)\n",
    "news_trn, news_test, lbl_trn, lbl_test = splits\n",
    "news_trn[:5, (0, 1, 97, 98, 99)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, escolhemos quais parâmetros vamos fazer os experimentos usando o KNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [KNeighborsClassifier()]\n",
    "pgrids = [\n",
    "    {'n_neighbors': [4, 8, 16], 'p': [2, 3]}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, fazemos o fine-tuning com os dados de treino com um GridSearch usando uma validação cruzada de 3 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = []\n",
    "for model, grid in zip(models, pgrids):\n",
    "    optimizer = GridSearchCV(model, grid, cv=3)\n",
    "    optimizer.fit(news_trn, lbl_trn)\n",
    "    best_models.append(optimizer.best_estimator_)\n",
    "\n",
    "best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo escolhido o melhor modelo, agora só precisamos testar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in best_models:\n",
    "    testacc = model.score(tst_vecs, labels_tst)\n",
    "    print(testacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idealmente, outras rodadas de experimentos seriam executadas. Dessa vez, fazendo alterações nas features. Mudando a dimensão, o tamanho da janela e outros parâmetros. Assim, podemos identificar casos onde uma featurepode ser melhor que a outra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
